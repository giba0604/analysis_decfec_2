{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4871ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1daeb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID CONJUNTO  DIST                       NOME           T01          T02  \\\n",
      "0             964    69                   PEDREIRA    117.901536     0.000000   \n",
      "1            2142    88                SIDERÓPOLIS    262.575384     0.000000   \n",
      "2            2922    69                 JAGUARIUNA    161.175144     0.000000   \n",
      "3            4536    83                     Forcel    227.891228     0.000000   \n",
      "4            5273    86                  URUSSANGA    255.300910     0.000000   \n",
      "...           ...   ...                        ...           ...          ...   \n",
      "3056        16717    32        CONJ_BERNARDO_SAYAO   4781.173152   598.362212   \n",
      "3057        16718    32                CONJ_PARANA  13150.115595    11.156815   \n",
      "3058        16719    32  CONJ_PARAISO_I_NAO_URBANO  16919.943701  1058.633147   \n",
      "3059        16720    32              CONJ_ALVORADA  14635.651923   391.643653   \n",
      "3060        16721    32     CONJ_GURUPI_NAO_URBANO   7012.198467   223.703590   \n",
      "\n",
      "             T03        T04       T05         T06       T07  ...       SE158  \\\n",
      "0       0.052702   0.000000   0.00000    8.157338  0.069188  ...  185.378476   \n",
      "1       4.893834  37.271785   0.00000   49.657270  0.189116  ...   73.000000   \n",
      "2       0.328161  10.276213   0.00000   66.557519  0.412952  ...  176.507072   \n",
      "3       0.000000   0.000000   0.00000    0.000000  0.000000  ...  495.978151   \n",
      "4       0.000000  56.077966   0.00000  173.203290  0.678428  ...   68.166893   \n",
      "...          ...        ...       ...         ...       ...  ...         ...   \n",
      "3056  123.414622  12.529034   0.00000  315.883554  0.066068  ...  361.715379   \n",
      "3057  193.203604  15.201067  74.74256  310.824086  0.023637  ...  484.468784   \n",
      "3058  255.687376   0.000000   0.00000  720.944533  0.042609  ...  281.441339   \n",
      "3059   34.115447  24.749975   0.00000  597.874800  0.040851  ...  265.202250   \n",
      "3060   43.867183   0.000000   0.00000  260.487623  0.037148  ...  374.193109   \n",
      "\n",
      "            SE159        SE160        SE161        SE162        SE163  \\\n",
      "0      993.387389  4180.361719  5197.702506  1254.521493   662.963736   \n",
      "1      335.000000  1211.000000  1588.000000   457.000000   197.000000   \n",
      "2     1085.191847  3470.604453  4703.435610  1623.779164  1144.147548   \n",
      "3     1146.095606  2440.007484  1821.965113   491.748189   277.590777   \n",
      "4      404.256382  1901.273085  2628.549973   765.892586   407.453150   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "3056   665.167559   897.017215   450.661247   127.458301    85.731255   \n",
      "3057   511.099951   619.738544   213.398828    50.578798    38.290962   \n",
      "3058   508.546073   705.293135   342.039191    85.070661    56.531806   \n",
      "3059   549.248712   809.263569   355.289162    84.512281    56.821797   \n",
      "3060   938.154457  1466.755805   865.736330   272.733333   201.026667   \n",
      "\n",
      "           SE164       SE165     DEC     FEC  \n",
      "0     357.873230  218.061475   5.638   3.352  \n",
      "1      91.000000   52.000000   2.664   2.808  \n",
      "2     852.674166  430.977462   4.574   3.330  \n",
      "3     150.517504  127.157774   0.482   0.884  \n",
      "4     213.662955   53.083650   4.244   4.490  \n",
      "...          ...         ...     ...     ...  \n",
      "3056   67.283091  130.623757  43.715  14.485  \n",
      "3057   33.691646  270.588080  21.270   8.910  \n",
      "3058   43.637546  126.645938  39.775   9.405  \n",
      "3059   43.476898  119.339316  25.370   7.635  \n",
      "3060  157.772734  176.892135  31.985   9.885  \n",
      "\n",
      "[3061 rows x 283 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('AtributosConjuntos_Vfinal.xlsx')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677c45ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID CONJUNTO</th>\n",
       "      <th>DIST</th>\n",
       "      <th>NOME</th>\n",
       "      <th>T01</th>\n",
       "      <th>T02</th>\n",
       "      <th>T03</th>\n",
       "      <th>T04</th>\n",
       "      <th>T05</th>\n",
       "      <th>T06</th>\n",
       "      <th>T07</th>\n",
       "      <th>...</th>\n",
       "      <th>SE158</th>\n",
       "      <th>SE159</th>\n",
       "      <th>SE160</th>\n",
       "      <th>SE161</th>\n",
       "      <th>SE162</th>\n",
       "      <th>SE163</th>\n",
       "      <th>SE164</th>\n",
       "      <th>SE165</th>\n",
       "      <th>DEC</th>\n",
       "      <th>FEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>964</td>\n",
       "      <td>69</td>\n",
       "      <td>PEDREIRA</td>\n",
       "      <td>117.901536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.157338</td>\n",
       "      <td>0.069188</td>\n",
       "      <td>...</td>\n",
       "      <td>185.378476</td>\n",
       "      <td>993.387389</td>\n",
       "      <td>4180.361719</td>\n",
       "      <td>5197.702506</td>\n",
       "      <td>1254.521493</td>\n",
       "      <td>662.963736</td>\n",
       "      <td>357.873230</td>\n",
       "      <td>218.061475</td>\n",
       "      <td>5.638</td>\n",
       "      <td>3.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2142</td>\n",
       "      <td>88</td>\n",
       "      <td>SIDERÓPOLIS</td>\n",
       "      <td>262.575384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.893834</td>\n",
       "      <td>37.271785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.657270</td>\n",
       "      <td>0.189116</td>\n",
       "      <td>...</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1588.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.664</td>\n",
       "      <td>2.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2922</td>\n",
       "      <td>69</td>\n",
       "      <td>JAGUARIUNA</td>\n",
       "      <td>161.175144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328161</td>\n",
       "      <td>10.276213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.557519</td>\n",
       "      <td>0.412952</td>\n",
       "      <td>...</td>\n",
       "      <td>176.507072</td>\n",
       "      <td>1085.191847</td>\n",
       "      <td>3470.604453</td>\n",
       "      <td>4703.435610</td>\n",
       "      <td>1623.779164</td>\n",
       "      <td>1144.147548</td>\n",
       "      <td>852.674166</td>\n",
       "      <td>430.977462</td>\n",
       "      <td>4.574</td>\n",
       "      <td>3.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4536</td>\n",
       "      <td>83</td>\n",
       "      <td>Forcel</td>\n",
       "      <td>227.891228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>495.978151</td>\n",
       "      <td>1146.095606</td>\n",
       "      <td>2440.007484</td>\n",
       "      <td>1821.965113</td>\n",
       "      <td>491.748189</td>\n",
       "      <td>277.590777</td>\n",
       "      <td>150.517504</td>\n",
       "      <td>127.157774</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5273</td>\n",
       "      <td>86</td>\n",
       "      <td>URUSSANGA</td>\n",
       "      <td>255.300910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.077966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.203290</td>\n",
       "      <td>0.678428</td>\n",
       "      <td>...</td>\n",
       "      <td>68.166893</td>\n",
       "      <td>404.256382</td>\n",
       "      <td>1901.273085</td>\n",
       "      <td>2628.549973</td>\n",
       "      <td>765.892586</td>\n",
       "      <td>407.453150</td>\n",
       "      <td>213.662955</td>\n",
       "      <td>53.083650</td>\n",
       "      <td>4.244</td>\n",
       "      <td>4.490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID CONJUNTO  DIST         NOME         T01  T02       T03        T04  T05  \\\n",
       "0          964    69     PEDREIRA  117.901536  0.0  0.052702   0.000000  0.0   \n",
       "1         2142    88  SIDERÓPOLIS  262.575384  0.0  4.893834  37.271785  0.0   \n",
       "2         2922    69   JAGUARIUNA  161.175144  0.0  0.328161  10.276213  0.0   \n",
       "3         4536    83       Forcel  227.891228  0.0  0.000000   0.000000  0.0   \n",
       "4         5273    86    URUSSANGA  255.300910  0.0  0.000000  56.077966  0.0   \n",
       "\n",
       "          T06       T07  ...       SE158        SE159        SE160  \\\n",
       "0    8.157338  0.069188  ...  185.378476   993.387389  4180.361719   \n",
       "1   49.657270  0.189116  ...   73.000000   335.000000  1211.000000   \n",
       "2   66.557519  0.412952  ...  176.507072  1085.191847  3470.604453   \n",
       "3    0.000000  0.000000  ...  495.978151  1146.095606  2440.007484   \n",
       "4  173.203290  0.678428  ...   68.166893   404.256382  1901.273085   \n",
       "\n",
       "         SE161        SE162        SE163       SE164       SE165    DEC    FEC  \n",
       "0  5197.702506  1254.521493   662.963736  357.873230  218.061475  5.638  3.352  \n",
       "1  1588.000000   457.000000   197.000000   91.000000   52.000000  2.664  2.808  \n",
       "2  4703.435610  1623.779164  1144.147548  852.674166  430.977462  4.574  3.330  \n",
       "3  1821.965113   491.748189   277.590777  150.517504  127.157774  0.482  0.884  \n",
       "4  2628.549973   765.892586   407.453150  213.662955   53.083650  4.244  4.490  \n",
       "\n",
       "[5 rows x 283 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Essa função ajuda a entender a estrutura da base dados.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940c75c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3061 entries, 0 to 3060\n",
      "Columns: 283 entries, ID CONJUNTO to FEC\n",
      "dtypes: float64(267), int64(15), object(1)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Essa função nos ajudará a ver quais entradas possuem dados faltantes.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83583597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID CONJUNTO</th>\n",
       "      <th>DIST</th>\n",
       "      <th>T01</th>\n",
       "      <th>T02</th>\n",
       "      <th>T03</th>\n",
       "      <th>T04</th>\n",
       "      <th>T05</th>\n",
       "      <th>T06</th>\n",
       "      <th>T07</th>\n",
       "      <th>T08</th>\n",
       "      <th>...</th>\n",
       "      <th>SE158</th>\n",
       "      <th>SE159</th>\n",
       "      <th>SE160</th>\n",
       "      <th>SE161</th>\n",
       "      <th>SE162</th>\n",
       "      <th>SE163</th>\n",
       "      <th>SE164</th>\n",
       "      <th>SE165</th>\n",
       "      <th>DEC</th>\n",
       "      <th>FEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14758.127736</td>\n",
       "      <td>1954.248938</td>\n",
       "      <td>2756.543404</td>\n",
       "      <td>243.717656</td>\n",
       "      <td>44.899910</td>\n",
       "      <td>27.916428</td>\n",
       "      <td>9.268016</td>\n",
       "      <td>285.780244</td>\n",
       "      <td>0.271205</td>\n",
       "      <td>384.300740</td>\n",
       "      <td>...</td>\n",
       "      <td>9408.502783</td>\n",
       "      <td>27497.366228</td>\n",
       "      <td>56782.950281</td>\n",
       "      <td>57206.641097</td>\n",
       "      <td>22617.783893</td>\n",
       "      <td>20867.647466</td>\n",
       "      <td>28008.147487</td>\n",
       "      <td>11219.024301</td>\n",
       "      <td>16.050409</td>\n",
       "      <td>7.480595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1308.661113</td>\n",
       "      <td>2466.506938</td>\n",
       "      <td>14750.466260</td>\n",
       "      <td>2755.814989</td>\n",
       "      <td>231.734745</td>\n",
       "      <td>108.461692</td>\n",
       "      <td>159.697858</td>\n",
       "      <td>484.271068</td>\n",
       "      <td>0.449567</td>\n",
       "      <td>4619.576935</td>\n",
       "      <td>...</td>\n",
       "      <td>21811.934992</td>\n",
       "      <td>71994.202693</td>\n",
       "      <td>159042.242674</td>\n",
       "      <td>171860.730024</td>\n",
       "      <td>69090.881091</td>\n",
       "      <td>64678.311713</td>\n",
       "      <td>91640.034548</td>\n",
       "      <td>36890.122340</td>\n",
       "      <td>15.861462</td>\n",
       "      <td>6.085756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>964.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.135852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.089343</td>\n",
       "      <td>6.278046</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13704.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>96.038401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.001410</td>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>544.196972</td>\n",
       "      <td>1248.000000</td>\n",
       "      <td>1831.034008</td>\n",
       "      <td>852.802851</td>\n",
       "      <td>200.224544</td>\n",
       "      <td>121.883016</td>\n",
       "      <td>74.823950</td>\n",
       "      <td>241.609114</td>\n",
       "      <td>6.536000</td>\n",
       "      <td>3.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14856.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>641.028173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.270928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.201415</td>\n",
       "      <td>0.187217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1690.997764</td>\n",
       "      <td>2816.786881</td>\n",
       "      <td>4635.177957</td>\n",
       "      <td>3317.829864</td>\n",
       "      <td>892.491874</td>\n",
       "      <td>562.232469</td>\n",
       "      <td>372.513399</td>\n",
       "      <td>634.250376</td>\n",
       "      <td>11.013333</td>\n",
       "      <td>5.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15896.000000</td>\n",
       "      <td>4950.000000</td>\n",
       "      <td>1989.702632</td>\n",
       "      <td>32.135371</td>\n",
       "      <td>14.442636</td>\n",
       "      <td>26.640053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>336.385468</td>\n",
       "      <td>0.302142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4737.250859</td>\n",
       "      <td>10950.383651</td>\n",
       "      <td>23380.813993</td>\n",
       "      <td>22456.802143</td>\n",
       "      <td>7302.894954</td>\n",
       "      <td>5162.179927</td>\n",
       "      <td>3899.683589</td>\n",
       "      <td>2972.626132</td>\n",
       "      <td>19.062000</td>\n",
       "      <td>8.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16721.000000</td>\n",
       "      <td>7019.000000</td>\n",
       "      <td>472227.107905</td>\n",
       "      <td>111357.022216</td>\n",
       "      <td>7196.038526</td>\n",
       "      <td>3225.024917</td>\n",
       "      <td>7189.601530</td>\n",
       "      <td>5004.296194</td>\n",
       "      <td>9.120013</td>\n",
       "      <td>172424.120591</td>\n",
       "      <td>...</td>\n",
       "      <td>102249.000000</td>\n",
       "      <td>363890.000000</td>\n",
       "      <td>826887.000000</td>\n",
       "      <td>915173.000000</td>\n",
       "      <td>362806.000000</td>\n",
       "      <td>333099.000000</td>\n",
       "      <td>467277.000000</td>\n",
       "      <td>202464.000000</td>\n",
       "      <td>150.152500</td>\n",
       "      <td>59.695000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID CONJUNTO         DIST            T01            T02          T03  \\\n",
       "count   3061.000000  3061.000000    3061.000000    3061.000000  3061.000000   \n",
       "mean   14758.127736  1954.248938    2756.543404     243.717656    44.899910   \n",
       "std     1308.661113  2466.506938   14750.466260    2755.814989   231.734745   \n",
       "min      964.000000    26.000000       0.135852       0.000000     0.000000   \n",
       "25%    13704.000000    63.000000      96.038401       0.000000     0.000000   \n",
       "50%    14856.000000   385.000000     641.028173       0.000000     1.270928   \n",
       "75%    15896.000000  4950.000000    1989.702632      32.135371    14.442636   \n",
       "max    16721.000000  7019.000000  472227.107905  111357.022216  7196.038526   \n",
       "\n",
       "               T04          T05          T06          T07            T08  ...  \\\n",
       "count  3061.000000  3061.000000  3061.000000  3061.000000    3061.000000  ...   \n",
       "mean     27.916428     9.268016   285.780244     0.271205     384.300740  ...   \n",
       "std     108.461692   159.697858   484.271068     0.449567    4619.576935  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000       0.000000  ...   \n",
       "25%       0.000000     0.000000    22.001410     0.091102       0.000000  ...   \n",
       "50%       0.000000     0.000000   126.201415     0.187217       0.000000  ...   \n",
       "75%      26.640053     0.000000   336.385468     0.302142       0.000000  ...   \n",
       "max    3225.024917  7189.601530  5004.296194     9.120013  172424.120591  ...   \n",
       "\n",
       "               SE158          SE159          SE160          SE161  \\\n",
       "count    3061.000000    3061.000000    3061.000000    3061.000000   \n",
       "mean     9408.502783   27497.366228   56782.950281   57206.641097   \n",
       "std     21811.934992   71994.202693  159042.242674  171860.730024   \n",
       "min        11.000000      32.000000     111.000000      47.000000   \n",
       "25%       544.196972    1248.000000    1831.034008     852.802851   \n",
       "50%      1690.997764    2816.786881    4635.177957    3317.829864   \n",
       "75%      4737.250859   10950.383651   23380.813993   22456.802143   \n",
       "max    102249.000000  363890.000000  826887.000000  915173.000000   \n",
       "\n",
       "               SE162          SE163          SE164          SE165  \\\n",
       "count    3061.000000    3061.000000    3061.000000    3061.000000   \n",
       "mean    22617.783893   20867.647466   28008.147487   11219.024301   \n",
       "std     69090.881091   64678.311713   91640.034548   36890.122340   \n",
       "min         7.000000       4.000000       3.089343       6.278046   \n",
       "25%       200.224544     121.883016      74.823950     241.609114   \n",
       "50%       892.491874     562.232469     372.513399     634.250376   \n",
       "75%      7302.894954    5162.179927    3899.683589    2972.626132   \n",
       "max    362806.000000  333099.000000  467277.000000  202464.000000   \n",
       "\n",
       "               DEC          FEC  \n",
       "count  3061.000000  3061.000000  \n",
       "mean     16.050409     7.480595  \n",
       "std      15.861462     6.085756  \n",
       "min       0.266000     0.118000  \n",
       "25%       6.536000     3.910000  \n",
       "50%      11.013333     5.726000  \n",
       "75%      19.062000     8.712000  \n",
       "max     150.152500    59.695000  \n",
       "\n",
       "[8 rows x 282 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe() serve para entregar as estatísticas dos dados.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf6cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T01', 'T02', 'T03', 'T04', 'T05', 'T06', 'T07', 'T08', 'T09', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'BDGD01', 'BDGD02', 'BDGD03', 'BDGD04', 'BDGD05', 'BDGD06', 'BDGD07', 'BDGD08', 'BDGD09', 'BDGD10', 'BDGD11', 'BDGD12', 'BDGD13', 'BDGD14', 'BDGD15', 'BDGD16', 'BDGD17', 'BDGD18', 'BDGD19', 'BDGD20', 'BDGD21', 'BDGD22', 'BDGD23', 'BDGD24', 'BDGD25', 'BDGD26', 'BDGD27', 'BDGD28', 'BDGD29', 'BDGD30', 'BDGD31', 'BDGD32', 'BDGD33', 'BDGD34', 'BDGD35', 'BDGD36', 'BDGD37', 'BDGD38', 'BDGD39', 'BDGD40', 'BDGD41', 'BDGD42', 'BDGD43', 'BDGD44', 'BDGD45', 'BDGD46', 'BDGD47', 'BDGD48', 'BDGD49', 'BDGD50', 'BDGD51', 'BDGD52', 'BDGD53', 'BDGD54', 'BDGD55', 'BDGD56', 'BDGD57', 'BDGD58', 'BDGD59', 'BDGD60', 'C01', 'C02', 'C03', 'C04', 'C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29', 'C30', 'C31', 'C32', 'C33', 'C34', 'C35', 'C36', 'SE001', 'SE002', 'SE003', 'SE004', 'SE005', 'SE006', 'SE007', 'SE008', 'SE009', 'SE010', 'SE011', 'SE012', 'SE013', 'SE014', 'SE015', 'SE016', 'SE017', 'SE018', 'SE019', 'SE020', 'SE021', 'SE022', 'SE023', 'SE024', 'SE025', 'SE026', 'SE027', 'SE028', 'SE029', 'SE030', 'SE031', 'SE032', 'SE033', 'SE034', 'SE035', 'SE036', 'SE037', 'SE038', 'SE039', 'SE040', 'SE041', 'SE042', 'SE043', 'SE044', 'SE045', 'SE046', 'SE047', 'SE048', 'SE049', 'SE050', 'SE051', 'SE052', 'SE053', 'SE054', 'SE055', 'SE056', 'SE057', 'SE058', 'SE059', 'SE060', 'SE061', 'SE062', 'SE063', 'SE064', 'SE065', 'SE066', 'SE067', 'SE068', 'SE069', 'SE070', 'SE071', 'SE072', 'SE073', 'SE074', 'SE075', 'SE076', 'SE077', 'SE078', 'SE079', 'SE080', 'SE081', 'SE082', 'SE083', 'SE084', 'SE085', 'SE086', 'SE087', 'SE088', 'SE089', 'SE090', 'SE091', 'SE092', 'SE093', 'SE094', 'SE095', 'SE096', 'SE097', 'SE098', 'SE099', 'SE100', 'SE101', 'SE102', 'SE103', 'SE104', 'SE105', 'SE106', 'SE107', 'SE108', 'SE109', 'SE110', 'SE111', 'SE112', 'SE113', 'SE114', 'SE115', 'SE116', 'SE117', 'SE118', 'SE119', 'SE120', 'SE121', 'SE122', 'SE123', 'SE124', 'SE125', 'SE126', 'SE127', 'SE128', 'SE129', 'SE130', 'SE131', 'SE132', 'SE133', 'SE134', 'SE135', 'SE136', 'SE137', 'SE138', 'SE139', 'SE140', 'SE141', 'SE142', 'SE143', 'SE144', 'SE145', 'SE146', 'SE147', 'SE148', 'SE149', 'SE150', 'SE151', 'SE152', 'SE153', 'SE154', 'SE155', 'SE156', 'SE157', 'SE158', 'SE159', 'SE160', 'SE161', 'SE162', 'SE163', 'SE164', 'SE165']\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['ID CONJUNTO', 'DIST', 'NOME', 'DEC', 'FEC']\n",
    "feature_names = [col for col in df.columns if col not in target_columns]\n",
    "\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e41f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               T01          T02         T03        T04       T05         T06  \\\n",
      "0       117.901536     0.000000    0.052702   0.000000   0.00000    8.157338   \n",
      "1       262.575384     0.000000    4.893834  37.271785   0.00000   49.657270   \n",
      "2       161.175144     0.000000    0.328161  10.276213   0.00000   66.557519   \n",
      "3       227.891228     0.000000    0.000000   0.000000   0.00000    0.000000   \n",
      "4       255.300910     0.000000    0.000000  56.077966   0.00000  173.203290   \n",
      "...            ...          ...         ...        ...       ...         ...   \n",
      "3056   4781.173152   598.362212  123.414622  12.529034   0.00000  315.883554   \n",
      "3057  13150.115595    11.156815  193.203604  15.201067  74.74256  310.824086   \n",
      "3058  16919.943701  1058.633147  255.687376   0.000000   0.00000  720.944533   \n",
      "3059  14635.651923   391.643653   34.115447  24.749975   0.00000  597.874800   \n",
      "3060   7012.198467   223.703590   43.867183   0.000000   0.00000  260.487623   \n",
      "\n",
      "           T07          T08           T09          T10  ...       SE156  \\\n",
      "0     0.069188     0.000000    117.277069     1.738442  ...  128.845574   \n",
      "1     0.189116     0.000000     40.258837    26.669621  ...   32.000000   \n",
      "2     0.412952     0.000000     97.919594    18.897402  ...  329.163908   \n",
      "3     0.000000     0.000000      0.000000     8.510217  ...   53.202801   \n",
      "4     0.678428     0.000000      0.000000    14.721344  ...   76.922461   \n",
      "...        ...          ...           ...          ...  ...         ...   \n",
      "3056  0.066068     0.584131      0.000000   574.420568  ...   33.267980   \n",
      "3057  0.023637     0.000000    479.557402   145.081091  ...   15.301319   \n",
      "3058  0.042609  1480.162484  12670.247291  2347.911958  ...   20.514434   \n",
      "3059  0.040851     0.000000      0.000000   527.211298  ...   16.332188   \n",
      "3060  0.037148     0.000000    189.932510   268.860394  ...   71.388914   \n",
      "\n",
      "           SE157       SE158        SE159        SE160        SE161  \\\n",
      "0     218.061475  185.378476   993.387389  4180.361719  5197.702506   \n",
      "1      52.000000   73.000000   335.000000  1211.000000  1588.000000   \n",
      "2     430.977462  176.507072  1085.191847  3470.604453  4703.435610   \n",
      "3     127.157774  495.978151  1146.095606  2440.007484  1821.965113   \n",
      "4      53.083650   68.166893   404.256382  1901.273085  2628.549973   \n",
      "...          ...         ...          ...          ...          ...   \n",
      "3056  130.623757  361.715379   665.167559   897.017215   450.661247   \n",
      "3057  270.588080  484.468784   511.099951   619.738544   213.398828   \n",
      "3058  126.645938  281.441339   508.546073   705.293135   342.039191   \n",
      "3059  119.339316  265.202250   549.248712   809.263569   355.289162   \n",
      "3060  176.892135  374.193109   938.154457  1466.755805   865.736330   \n",
      "\n",
      "            SE162        SE163       SE164       SE165  \n",
      "0     1254.521493   662.963736  357.873230  218.061475  \n",
      "1      457.000000   197.000000   91.000000   52.000000  \n",
      "2     1623.779164  1144.147548  852.674166  430.977462  \n",
      "3      491.748189   277.590777  150.517504  127.157774  \n",
      "4      765.892586   407.453150  213.662955   53.083650  \n",
      "...           ...          ...         ...         ...  \n",
      "3056   127.458301    85.731255   67.283091  130.623757  \n",
      "3057    50.578798    38.290962   33.691646  270.588080  \n",
      "3058    85.070661    56.531806   43.637546  126.645938  \n",
      "3059    84.512281    56.821797   43.476898  119.339316  \n",
      "3060   272.733333   201.026667  157.772734  176.892135  \n",
      "\n",
      "[3061 rows x 278 columns]\n",
      "0        5.638\n",
      "1        2.664\n",
      "2        4.574\n",
      "3        0.482\n",
      "4        4.244\n",
      "         ...  \n",
      "3056    43.715\n",
      "3057    21.270\n",
      "3058    39.775\n",
      "3059    25.370\n",
      "3060    31.985\n",
      "Name: DEC, Length: 3061, dtype: float64\n",
      "0        3.352\n",
      "1        2.808\n",
      "2        3.330\n",
      "3        0.884\n",
      "4        4.490\n",
      "         ...  \n",
      "3056    14.485\n",
      "3057     8.910\n",
      "3058     9.405\n",
      "3059     7.635\n",
      "3060     9.885\n",
      "Name: FEC, Length: 3061, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Separando os dados de entrada e saída em diferentes dataframes.\n",
    "inputs, DEC, FEC = df.iloc[:, 3:281], df.iloc[:, 281], df.iloc[:, 282]\n",
    "\n",
    "print(inputs)\n",
    "print(DEC)\n",
    "print(FEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed63e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T01</th>\n",
       "      <th>T02</th>\n",
       "      <th>T03</th>\n",
       "      <th>T04</th>\n",
       "      <th>T05</th>\n",
       "      <th>T06</th>\n",
       "      <th>T07</th>\n",
       "      <th>T08</th>\n",
       "      <th>T09</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>SE156</th>\n",
       "      <th>SE157</th>\n",
       "      <th>SE158</th>\n",
       "      <th>SE159</th>\n",
       "      <th>SE160</th>\n",
       "      <th>SE161</th>\n",
       "      <th>SE162</th>\n",
       "      <th>SE163</th>\n",
       "      <th>SE164</th>\n",
       "      <th>SE165</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2756.543404</td>\n",
       "      <td>243.717656</td>\n",
       "      <td>44.899910</td>\n",
       "      <td>27.916428</td>\n",
       "      <td>9.268016</td>\n",
       "      <td>285.780244</td>\n",
       "      <td>0.271205</td>\n",
       "      <td>384.300740</td>\n",
       "      <td>472.647846</td>\n",
       "      <td>1289.877798</td>\n",
       "      <td>...</td>\n",
       "      <td>13320.650117</td>\n",
       "      <td>11219.024301</td>\n",
       "      <td>9408.502783</td>\n",
       "      <td>27497.366228</td>\n",
       "      <td>56782.950281</td>\n",
       "      <td>57206.641097</td>\n",
       "      <td>22617.783893</td>\n",
       "      <td>20867.647466</td>\n",
       "      <td>28008.147487</td>\n",
       "      <td>11219.024301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14750.466260</td>\n",
       "      <td>2755.814989</td>\n",
       "      <td>231.734745</td>\n",
       "      <td>108.461692</td>\n",
       "      <td>159.697858</td>\n",
       "      <td>484.271068</td>\n",
       "      <td>0.449567</td>\n",
       "      <td>4619.576935</td>\n",
       "      <td>5099.576624</td>\n",
       "      <td>13580.733334</td>\n",
       "      <td>...</td>\n",
       "      <td>43638.567850</td>\n",
       "      <td>36890.122340</td>\n",
       "      <td>21811.934992</td>\n",
       "      <td>71994.202693</td>\n",
       "      <td>159042.242674</td>\n",
       "      <td>171860.730024</td>\n",
       "      <td>69090.881091</td>\n",
       "      <td>64678.311713</td>\n",
       "      <td>91640.034548</td>\n",
       "      <td>36890.122340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.135852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008708</td>\n",
       "      <td>6.278046</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.089343</td>\n",
       "      <td>6.278046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>96.038401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.001410</td>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.597028</td>\n",
       "      <td>241.609114</td>\n",
       "      <td>544.196972</td>\n",
       "      <td>1248.000000</td>\n",
       "      <td>1831.034008</td>\n",
       "      <td>852.802851</td>\n",
       "      <td>200.224544</td>\n",
       "      <td>121.883016</td>\n",
       "      <td>74.823950</td>\n",
       "      <td>241.609114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>641.028173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.270928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.201415</td>\n",
       "      <td>0.187217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216285</td>\n",
       "      <td>19.586551</td>\n",
       "      <td>...</td>\n",
       "      <td>143.467013</td>\n",
       "      <td>634.250376</td>\n",
       "      <td>1690.997764</td>\n",
       "      <td>2816.786881</td>\n",
       "      <td>4635.177957</td>\n",
       "      <td>3317.829864</td>\n",
       "      <td>892.491874</td>\n",
       "      <td>562.232469</td>\n",
       "      <td>372.513399</td>\n",
       "      <td>634.250376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1989.702632</td>\n",
       "      <td>32.135371</td>\n",
       "      <td>14.442636</td>\n",
       "      <td>26.640053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>336.385468</td>\n",
       "      <td>0.302142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.648045</td>\n",
       "      <td>223.833309</td>\n",
       "      <td>...</td>\n",
       "      <td>1616.880161</td>\n",
       "      <td>2972.626132</td>\n",
       "      <td>4737.250859</td>\n",
       "      <td>10950.383651</td>\n",
       "      <td>23380.813993</td>\n",
       "      <td>22456.802143</td>\n",
       "      <td>7302.894954</td>\n",
       "      <td>5162.179927</td>\n",
       "      <td>3899.683589</td>\n",
       "      <td>2972.626132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>472227.107905</td>\n",
       "      <td>111357.022216</td>\n",
       "      <td>7196.038526</td>\n",
       "      <td>3225.024917</td>\n",
       "      <td>7189.601530</td>\n",
       "      <td>5004.296194</td>\n",
       "      <td>9.120013</td>\n",
       "      <td>172424.120591</td>\n",
       "      <td>180665.101277</td>\n",
       "      <td>445798.158788</td>\n",
       "      <td>...</td>\n",
       "      <td>226082.000000</td>\n",
       "      <td>202464.000000</td>\n",
       "      <td>102249.000000</td>\n",
       "      <td>363890.000000</td>\n",
       "      <td>826887.000000</td>\n",
       "      <td>915173.000000</td>\n",
       "      <td>362806.000000</td>\n",
       "      <td>333099.000000</td>\n",
       "      <td>467277.000000</td>\n",
       "      <td>202464.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T01            T02          T03          T04          T05  \\\n",
       "count    3061.000000    3061.000000  3061.000000  3061.000000  3061.000000   \n",
       "mean     2756.543404     243.717656    44.899910    27.916428     9.268016   \n",
       "std     14750.466260    2755.814989   231.734745   108.461692   159.697858   \n",
       "min         0.135852       0.000000     0.000000     0.000000     0.000000   \n",
       "25%        96.038401       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       641.028173       0.000000     1.270928     0.000000     0.000000   \n",
       "75%      1989.702632      32.135371    14.442636    26.640053     0.000000   \n",
       "max    472227.107905  111357.022216  7196.038526  3225.024917  7189.601530   \n",
       "\n",
       "               T06          T07            T08            T09            T10  \\\n",
       "count  3061.000000  3061.000000    3061.000000    3061.000000    3061.000000   \n",
       "mean    285.780244     0.271205     384.300740     472.647846    1289.877798   \n",
       "std     484.271068     0.449567    4619.576935    5099.576624   13580.733334   \n",
       "min       0.000000     0.000000       0.000000       0.000000       0.000000   \n",
       "25%      22.001410     0.091102       0.000000       0.000000       0.000000   \n",
       "50%     126.201415     0.187217       0.000000       0.216285      19.586551   \n",
       "75%     336.385468     0.302142       0.000000      41.648045     223.833309   \n",
       "max    5004.296194     9.120013  172424.120591  180665.101277  445798.158788   \n",
       "\n",
       "       ...          SE156          SE157          SE158          SE159  \\\n",
       "count  ...    3061.000000    3061.000000    3061.000000    3061.000000   \n",
       "mean   ...   13320.650117   11219.024301    9408.502783   27497.366228   \n",
       "std    ...   43638.567850   36890.122340   21811.934992   71994.202693   \n",
       "min    ...       1.008708       6.278046      11.000000      32.000000   \n",
       "25%    ...      29.597028     241.609114     544.196972    1248.000000   \n",
       "50%    ...     143.467013     634.250376    1690.997764    2816.786881   \n",
       "75%    ...    1616.880161    2972.626132    4737.250859   10950.383651   \n",
       "max    ...  226082.000000  202464.000000  102249.000000  363890.000000   \n",
       "\n",
       "               SE160          SE161          SE162          SE163  \\\n",
       "count    3061.000000    3061.000000    3061.000000    3061.000000   \n",
       "mean    56782.950281   57206.641097   22617.783893   20867.647466   \n",
       "std    159042.242674  171860.730024   69090.881091   64678.311713   \n",
       "min       111.000000      47.000000       7.000000       4.000000   \n",
       "25%      1831.034008     852.802851     200.224544     121.883016   \n",
       "50%      4635.177957    3317.829864     892.491874     562.232469   \n",
       "75%     23380.813993   22456.802143    7302.894954    5162.179927   \n",
       "max    826887.000000  915173.000000  362806.000000  333099.000000   \n",
       "\n",
       "               SE164          SE165  \n",
       "count    3061.000000    3061.000000  \n",
       "mean    28008.147487   11219.024301  \n",
       "std     91640.034548   36890.122340  \n",
       "min         3.089343       6.278046  \n",
       "25%        74.823950     241.609114  \n",
       "50%       372.513399     634.250376  \n",
       "75%      3899.683589    2972.626132  \n",
       "max    467277.000000  202464.000000  \n",
       "\n",
       "[8 rows x 278 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Essa parte do código preenche os valores de atributos vazios pela média da coluna do atributo. A vantagem de fazer isso é que\n",
    "#a média nem o desvio padrão dos dados são alterados.\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "\n",
    "inputs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b973060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2448, 278) (613, 278) (2448,) (613,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, FEC, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0e5831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aqui está sendo chamado um módulo para poder normalizar os dados. Foi escolhido o uso do MinMaxScaler, que nós dá valores no intervalo [0, 1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a513e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.067191</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060136</td>\n",
       "      <td>0.056335</td>\n",
       "      <td>0.093546</td>\n",
       "      <td>0.076868</td>\n",
       "      <td>0.069753</td>\n",
       "      <td>0.063510</td>\n",
       "      <td>0.063424</td>\n",
       "      <td>0.063824</td>\n",
       "      <td>0.061187</td>\n",
       "      <td>0.056335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029310</td>\n",
       "      <td>0.025659</td>\n",
       "      <td>0.033595</td>\n",
       "      <td>0.034990</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.115147</td>\n",
       "      <td>0.047207</td>\n",
       "      <td>0.040482</td>\n",
       "      <td>0.026278</td>\n",
       "      <td>0.028799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194391</td>\n",
       "      <td>0.183123</td>\n",
       "      <td>0.215420</td>\n",
       "      <td>0.199394</td>\n",
       "      <td>0.193682</td>\n",
       "      <td>0.188884</td>\n",
       "      <td>0.191601</td>\n",
       "      <td>0.195493</td>\n",
       "      <td>0.197586</td>\n",
       "      <td>0.183123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.001166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028972</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078885</td>\n",
       "      <td>0.033278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007495</td>\n",
       "      <td>0.015095</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>0.030775</td>\n",
       "      <td>0.028703</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>0.020477</td>\n",
       "      <td>0.015966</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.015095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1            2            3            4    \\\n",
       "count  2448.000000  2448.000000  2448.000000  2448.000000  2448.000000   \n",
       "mean      0.005719     0.002153     0.006536     0.008627     0.001731   \n",
       "std       0.029310     0.025659     0.033595     0.034990     0.023760   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000193     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.001359     0.000000     0.000171     0.000000     0.000000   \n",
       "75%       0.004234     0.000299     0.002080     0.008111     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               5            6            7            8            9    ...  \\\n",
       "count  2448.000000  2448.000000  2448.000000  2448.000000  2448.000000  ...   \n",
       "mean      0.067191     0.030071     0.003822     0.002435     0.002714  ...   \n",
       "std       0.115147     0.047207     0.040482     0.026278     0.028799  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.005010     0.009991     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.028972     0.020335     0.000000     0.000001     0.000044  ...   \n",
       "75%       0.078885     0.033278     0.000000     0.000238     0.000489  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "               268          269          270          271          272  \\\n",
       "count  2448.000000  2448.000000  2448.000000  2448.000000  2448.000000   \n",
       "mean      0.060136     0.056335     0.093546     0.076868     0.069753   \n",
       "std       0.194391     0.183123     0.215420     0.199394     0.193682   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000124     0.001166     0.005190     0.003324     0.002052   \n",
       "50%       0.000641     0.003101     0.016531     0.007685     0.005496   \n",
       "75%       0.007495     0.015095     0.047166     0.030775     0.028703   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               273          274          275          276          277  \n",
       "count  2448.000000  2448.000000  2448.000000  2448.000000  2448.000000  \n",
       "mean      0.063510     0.063424     0.063824     0.061187     0.056335  \n",
       "std       0.188884     0.191601     0.195493     0.197586     0.183123  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000871     0.000532     0.000350     0.000152     0.001166  \n",
       "50%       0.003667     0.002532     0.001687     0.000792     0.003101  \n",
       "75%       0.025194     0.020477     0.015966     0.008518     0.015095  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 278 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf7a26d",
   "metadata": {},
   "source": [
    "# Modelo GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0826991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "GBR = GradientBoostingRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3510ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    " param_grid = {\n",
    "     'n_estimators': [10, 50, 100, 500],\n",
    "     'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "     'max_depth': [3, 5, 7, 9]\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a786703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GS = GridSearchCV(estimator = GBR,\n",
    "                        param_grid = param_grid,\n",
    "                        scoring = [\"r2\", \"neg_root_mean_squared_error\"],\n",
    "                        refit = \"r2\",\n",
    "                        cv = 5,\n",
    "                        verbose = 3,\n",
    "                        n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bd0f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 500]},\n",
       "             refit=&#x27;r2&#x27;, scoring=[&#x27;r2&#x27;, &#x27;neg_root_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 500]},\n",
       "             refit=&#x27;r2&#x27;, scoring=[&#x27;r2&#x27;, &#x27;neg_root_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
       "                         'max_depth': [3, 5, 7, 9],\n",
       "                         'n_estimators': [10, 50, 100, 500]},\n",
       "             refit='r2', scoring=['r2', 'neg_root_mean_squared_error'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a631a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f270b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "116265a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7157809332285799"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1a2ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.DataFrame(GS.cv_results_)\n",
    "excel = excel.sort_values(\"rank_test_r2\")\n",
    "excel.to_csv(\"cv_gbr_FEC_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d10e6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBR = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 3, n_estimators = 500, random_state = 42)\n",
    "\n",
    "GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "041cce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características ordenadas por importância (maior para menor):\n",
      "BDGD04: 27.614900 %\n",
      "SE094: 4.400725 %\n",
      "BDGD57: 3.881576 %\n",
      "BDGD03: 3.765415 %\n",
      "C27: 3.635005 %\n",
      "SE022: 3.255941 %\n",
      "BDGD34: 3.218803 %\n",
      "SE128: 3.195178 %\n",
      "C01: 3.175385 %\n",
      "T14: 3.151771 %\n",
      "BDGD56: 1.816655 %\n",
      "SE095: 1.445509 %\n",
      "C03: 1.310607 %\n",
      "BDGD48: 1.200672 %\n",
      "SE007: 1.189334 %\n",
      "BDGD27: 1.070291 %\n",
      "BDGD58: 1.052806 %\n",
      "\n",
      "Soma das importâncias: 68.380572 %\n"
     ]
    }
   ],
   "source": [
    "# Acesse as importâncias das características\n",
    "importances = GBR.feature_importances_\n",
    "\n",
    "# Associe as importâncias às características\n",
    "feature_importance_dict = dict(zip(feature_names, importances))\n",
    "\n",
    "# Filtre e ordene as importâncias em ordem decrescente\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Inicialize a variável para a soma das importâncias\n",
    "total_importance = 0\n",
    "\n",
    "# Imprima as importâncias das características com mais de 0.1%\n",
    "print(\"Características ordenadas por importância (maior para menor):\")\n",
    "for feature, importance in sorted_features:\n",
    "    percentage_importance = importance * 100\n",
    "    if percentage_importance >= 1:\n",
    "        print(f\"{feature}: {percentage_importance:.6f} %\")\n",
    "        total_importance += percentage_importance\n",
    "\n",
    "# Imprima a soma das importâncias\n",
    "print(f\"\\nSoma das importâncias: {total_importance:.6f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a5672",
   "metadata": {},
   "source": [
    "# Modelo Forward Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a8bb800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['SE094']\n",
      "(2448, 1)\n",
      "(613, 1)\n",
      "Tempo de treino: 9.397415400017053\n",
      "23.274804893809357 0.27512000928078073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='forward', estimator=LR, tol=1.0, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4b57813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['SE094']\n",
      "(2448, 1)\n",
      "(613, 1)\n",
      "Tempo de treino: 4.639801399986027\n",
      "23.274804893809357 0.27512000928078073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='forward', estimator=LR, tol=0.1, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4852f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T03' 'BDGD02' 'BDGD48' 'C04' 'SE024' 'SE094']\n",
      "(2448, 6)\n",
      "(613, 6)\n",
      "Tempo de treino: 15.817851200001314\n",
      "16.464406626026452 0.4872258230853781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='forward', estimator=LR, tol=0.01, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c80100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T03' 'T12' 'T14' 'BDGD02' 'BDGD04' 'BDGD15' 'BDGD19' 'BDGD20' 'BDGD21'\n",
      " 'BDGD25' 'BDGD27' 'BDGD31' 'BDGD48' 'BDGD50' 'BDGD52' 'BDGD56' 'BDGD57'\n",
      " 'BDGD58' 'BDGD60' 'C04' 'C05' 'C20' 'C26' 'C36' 'SE003' 'SE009' 'SE022'\n",
      " 'SE024' 'SE026' 'SE031' 'SE073' 'SE077' 'SE094']\n",
      "(2448, 33)\n",
      "(613, 33)\n",
      "Tempo de treino: 84.962855699996\n",
      "14.327228606408077 0.5537869646328349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='forward', estimator=LR, tol=0.001, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cb0e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T03' 'T12' 'T14' 'BDGD02' 'BDGD03' 'BDGD04' 'BDGD07' 'BDGD13' 'BDGD14'\n",
      " 'BDGD15' 'BDGD18' 'BDGD19' 'BDGD20' 'BDGD21' 'BDGD23' 'BDGD24' 'BDGD25'\n",
      " 'BDGD27' 'BDGD28' 'BDGD29' 'BDGD31' 'BDGD45' 'BDGD48' 'BDGD50' 'BDGD52'\n",
      " 'BDGD53' 'BDGD56' 'BDGD57' 'BDGD58' 'BDGD59' 'BDGD60' 'C01' 'C02' 'C04'\n",
      " 'C05' 'C06' 'C07' 'C08' 'C14' 'C18' 'C20' 'C21' 'C25' 'C26' 'C33' 'C35'\n",
      " 'C36' 'SE001' 'SE002' 'SE003' 'SE009' 'SE012' 'SE020' 'SE022' 'SE024'\n",
      " 'SE026' 'SE029' 'SE031' 'SE032' 'SE035' 'SE037' 'SE039' 'SE046' 'SE047'\n",
      " 'SE050' 'SE051' 'SE053' 'SE058' 'SE060' 'SE061' 'SE066' 'SE069' 'SE070'\n",
      " 'SE073' 'SE074' 'SE077' 'SE081' 'SE085' 'SE089' 'SE090' 'SE091' 'SE094'\n",
      " 'SE097' 'SE102' 'SE113' 'SE116' 'SE123' 'SE124' 'SE127' 'SE128' 'SE131'\n",
      " 'SE136' 'SE149' 'SE151' 'SE160' 'SE161']\n",
      "(2448, 96)\n",
      "(613, 96)\n",
      "Tempo de treino: 1244.7974947000039\n",
      "13.206825179697965 0.5886812646822169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='forward', estimator=LR, tol=0.0001, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c44225a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T01' 'T02' 'T03' 'T04' 'T05' 'T06' 'T07' 'T08' 'T09' 'T10' 'T11' 'T12'\n",
      " 'T13' 'T14' 'T15' 'T16' 'T17' 'BDGD01' 'BDGD02' 'BDGD03' 'BDGD04'\n",
      " 'BDGD05' 'BDGD06' 'BDGD07' 'BDGD08' 'BDGD09' 'BDGD10' 'BDGD11' 'BDGD12'\n",
      " 'BDGD13' 'BDGD14' 'BDGD15' 'BDGD16' 'BDGD17' 'BDGD18' 'BDGD19' 'BDGD20'\n",
      " 'BDGD21' 'BDGD22' 'BDGD23' 'BDGD24' 'BDGD25' 'BDGD26' 'BDGD27' 'BDGD28'\n",
      " 'BDGD29' 'BDGD30' 'BDGD31' 'BDGD32' 'BDGD33' 'BDGD34' 'BDGD35' 'BDGD36'\n",
      " 'BDGD37' 'BDGD38' 'BDGD39' 'BDGD40' 'BDGD41' 'BDGD42' 'BDGD43' 'BDGD44'\n",
      " 'BDGD45' 'BDGD46' 'BDGD47' 'BDGD48' 'BDGD49' 'BDGD50' 'BDGD51' 'BDGD52'\n",
      " 'BDGD53' 'BDGD54' 'BDGD55' 'BDGD56' 'BDGD57' 'BDGD58' 'BDGD59' 'BDGD60'\n",
      " 'C01' 'C02' 'C03' 'C04' 'C05' 'C06' 'C07' 'C08' 'C09' 'C10' 'C11' 'C12'\n",
      " 'C13' 'C14' 'C15' 'C16' 'C17' 'C18' 'C19' 'C20' 'C21' 'C22' 'C23' 'C24'\n",
      " 'C25' 'C26' 'C27' 'C28' 'C29' 'C30' 'C31' 'C32' 'C33' 'C34' 'C35' 'C36'\n",
      " 'SE001' 'SE002' 'SE003' 'SE004' 'SE005' 'SE006' 'SE007' 'SE008' 'SE009'\n",
      " 'SE010' 'SE011' 'SE012' 'SE013' 'SE014' 'SE015' 'SE016' 'SE017' 'SE018'\n",
      " 'SE019' 'SE020' 'SE021' 'SE022' 'SE023' 'SE024' 'SE025' 'SE026' 'SE027'\n",
      " 'SE028' 'SE029' 'SE030' 'SE031' 'SE032' 'SE033' 'SE034' 'SE035' 'SE036'\n",
      " 'SE037' 'SE038' 'SE039' 'SE040' 'SE041' 'SE042' 'SE043' 'SE044' 'SE045'\n",
      " 'SE046' 'SE047' 'SE048' 'SE049' 'SE050' 'SE051' 'SE052' 'SE053' 'SE054'\n",
      " 'SE055' 'SE056' 'SE057' 'SE058' 'SE059' 'SE060' 'SE061' 'SE062' 'SE063'\n",
      " 'SE064' 'SE065' 'SE066' 'SE067' 'SE068' 'SE069' 'SE070' 'SE071' 'SE072'\n",
      " 'SE073' 'SE074' 'SE076' 'SE077' 'SE078' 'SE079' 'SE080' 'SE081' 'SE082'\n",
      " 'SE083' 'SE084' 'SE085' 'SE086' 'SE087' 'SE088' 'SE089' 'SE090' 'SE091'\n",
      " 'SE092' 'SE093' 'SE094' 'SE095' 'SE096' 'SE097' 'SE098' 'SE099' 'SE100'\n",
      " 'SE101' 'SE102' 'SE103' 'SE104' 'SE105' 'SE106' 'SE107' 'SE108' 'SE109'\n",
      " 'SE110' 'SE111' 'SE112' 'SE113' 'SE114' 'SE115' 'SE116' 'SE117' 'SE118'\n",
      " 'SE119' 'SE120' 'SE121' 'SE122' 'SE123' 'SE124' 'SE125' 'SE126' 'SE127'\n",
      " 'SE128' 'SE129' 'SE130' 'SE131' 'SE132' 'SE133' 'SE134' 'SE135' 'SE136'\n",
      " 'SE137' 'SE138' 'SE139' 'SE140' 'SE141' 'SE142' 'SE143' 'SE144' 'SE145'\n",
      " 'SE146' 'SE147' 'SE148' 'SE149' 'SE150' 'SE151' 'SE152' 'SE153' 'SE154'\n",
      " 'SE155' 'SE156' 'SE157' 'SE158' 'SE159' 'SE160' 'SE161' 'SE162' 'SE163'\n",
      " 'SE164' 'SE165']\n",
      "(2448, 277)\n",
      "(613, 277)\n",
      "Tempo de treino: 87.18328369999654\n",
      "18.267734976922263 0.43106223141511024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='backward', estimator=LR, tol=1.0, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba93637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T01' 'T02' 'T03' 'T04' 'T05' 'T06' 'T07' 'T08' 'T09' 'T10' 'T11' 'T12'\n",
      " 'T13' 'T14' 'T15' 'T16' 'T17' 'BDGD01' 'BDGD02' 'BDGD03' 'BDGD04'\n",
      " 'BDGD05' 'BDGD06' 'BDGD07' 'BDGD09' 'BDGD10' 'BDGD11' 'BDGD12' 'BDGD13'\n",
      " 'BDGD14' 'BDGD15' 'BDGD16' 'BDGD17' 'BDGD18' 'BDGD19' 'BDGD20' 'BDGD21'\n",
      " 'BDGD22' 'BDGD23' 'BDGD24' 'BDGD25' 'BDGD26' 'BDGD27' 'BDGD28' 'BDGD29'\n",
      " 'BDGD30' 'BDGD31' 'BDGD32' 'BDGD33' 'BDGD34' 'BDGD35' 'BDGD36' 'BDGD37'\n",
      " 'BDGD38' 'BDGD39' 'BDGD40' 'BDGD41' 'BDGD42' 'BDGD43' 'BDGD44' 'BDGD45'\n",
      " 'BDGD46' 'BDGD47' 'BDGD48' 'BDGD49' 'BDGD50' 'BDGD51' 'BDGD52' 'BDGD53'\n",
      " 'BDGD54' 'BDGD55' 'BDGD56' 'BDGD57' 'BDGD58' 'BDGD59' 'BDGD60' 'C01'\n",
      " 'C02' 'C03' 'C04' 'C05' 'C06' 'C07' 'C08' 'C09' 'C10' 'C11' 'C12' 'C13'\n",
      " 'C14' 'C15' 'C16' 'C17' 'C18' 'C19' 'C20' 'C21' 'C22' 'C23' 'C24' 'C25'\n",
      " 'C26' 'C27' 'C28' 'C29' 'C30' 'C31' 'C32' 'C33' 'C34' 'C35' 'C36' 'SE001'\n",
      " 'SE002' 'SE003' 'SE004' 'SE005' 'SE006' 'SE007' 'SE008' 'SE009' 'SE010'\n",
      " 'SE011' 'SE012' 'SE013' 'SE014' 'SE015' 'SE016' 'SE017' 'SE018' 'SE019'\n",
      " 'SE020' 'SE021' 'SE022' 'SE023' 'SE024' 'SE025' 'SE026' 'SE027' 'SE028'\n",
      " 'SE029' 'SE030' 'SE031' 'SE032' 'SE033' 'SE034' 'SE035' 'SE036' 'SE037'\n",
      " 'SE038' 'SE039' 'SE040' 'SE041' 'SE042' 'SE043' 'SE044' 'SE045' 'SE046'\n",
      " 'SE047' 'SE048' 'SE049' 'SE050' 'SE051' 'SE052' 'SE053' 'SE054' 'SE055'\n",
      " 'SE056' 'SE057' 'SE058' 'SE059' 'SE060' 'SE061' 'SE062' 'SE063' 'SE064'\n",
      " 'SE065' 'SE066' 'SE067' 'SE068' 'SE069' 'SE070' 'SE071' 'SE072' 'SE073'\n",
      " 'SE074' 'SE076' 'SE077' 'SE078' 'SE079' 'SE080' 'SE081' 'SE082' 'SE083'\n",
      " 'SE084' 'SE085' 'SE086' 'SE087' 'SE088' 'SE089' 'SE090' 'SE091' 'SE092'\n",
      " 'SE093' 'SE094' 'SE095' 'SE096' 'SE097' 'SE098' 'SE099' 'SE100' 'SE101'\n",
      " 'SE102' 'SE103' 'SE104' 'SE105' 'SE106' 'SE107' 'SE108' 'SE109' 'SE110'\n",
      " 'SE111' 'SE112' 'SE113' 'SE114' 'SE115' 'SE116' 'SE117' 'SE118' 'SE119'\n",
      " 'SE120' 'SE121' 'SE122' 'SE123' 'SE124' 'SE125' 'SE126' 'SE127' 'SE128'\n",
      " 'SE129' 'SE130' 'SE131' 'SE132' 'SE133' 'SE134' 'SE135' 'SE136' 'SE137'\n",
      " 'SE138' 'SE139' 'SE140' 'SE141' 'SE142' 'SE143' 'SE144' 'SE145' 'SE146'\n",
      " 'SE147' 'SE148' 'SE149' 'SE150' 'SE151' 'SE152' 'SE153' 'SE154' 'SE155'\n",
      " 'SE156' 'SE157' 'SE158' 'SE159' 'SE160' 'SE161' 'SE162' 'SE163' 'SE164'\n",
      " 'SE165']\n",
      "(2448, 276)\n",
      "(613, 276)\n",
      "Tempo de treino: 129.9369328999892\n",
      "14.190389011024765 0.5580487526514258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='backward', estimator=LR, tol=0.1, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b20e826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T01' 'T02' 'T03' 'T04' 'T05' 'T06' 'T07' 'T08' 'T09' 'T10' 'T11' 'T12'\n",
      " 'T13' 'T14' 'T15' 'T16' 'T17' 'BDGD01' 'BDGD02' 'BDGD03' 'BDGD04'\n",
      " 'BDGD05' 'BDGD06' 'BDGD07' 'BDGD09' 'BDGD10' 'BDGD11' 'BDGD12' 'BDGD13'\n",
      " 'BDGD14' 'BDGD15' 'BDGD16' 'BDGD17' 'BDGD18' 'BDGD19' 'BDGD20' 'BDGD21'\n",
      " 'BDGD22' 'BDGD23' 'BDGD24' 'BDGD25' 'BDGD26' 'BDGD27' 'BDGD28' 'BDGD29'\n",
      " 'BDGD30' 'BDGD31' 'BDGD32' 'BDGD33' 'BDGD34' 'BDGD35' 'BDGD36' 'BDGD37'\n",
      " 'BDGD38' 'BDGD39' 'BDGD40' 'BDGD41' 'BDGD42' 'BDGD43' 'BDGD44' 'BDGD45'\n",
      " 'BDGD46' 'BDGD47' 'BDGD48' 'BDGD49' 'BDGD50' 'BDGD51' 'BDGD52' 'BDGD53'\n",
      " 'BDGD54' 'BDGD55' 'BDGD56' 'BDGD57' 'BDGD58' 'BDGD59' 'BDGD60' 'C01'\n",
      " 'C02' 'C03' 'C04' 'C05' 'C06' 'C07' 'C08' 'C09' 'C10' 'C11' 'C12' 'C13'\n",
      " 'C14' 'C15' 'C16' 'C17' 'C18' 'C19' 'C20' 'C21' 'C22' 'C23' 'C24' 'C25'\n",
      " 'C26' 'C27' 'C28' 'C29' 'C30' 'C31' 'C32' 'C33' 'C35' 'C36' 'SE001'\n",
      " 'SE002' 'SE003' 'SE004' 'SE005' 'SE006' 'SE007' 'SE008' 'SE009' 'SE010'\n",
      " 'SE011' 'SE012' 'SE013' 'SE014' 'SE015' 'SE016' 'SE017' 'SE018' 'SE019'\n",
      " 'SE020' 'SE021' 'SE022' 'SE023' 'SE024' 'SE025' 'SE026' 'SE027' 'SE028'\n",
      " 'SE029' 'SE030' 'SE031' 'SE032' 'SE033' 'SE034' 'SE035' 'SE036' 'SE037'\n",
      " 'SE038' 'SE039' 'SE040' 'SE041' 'SE042' 'SE043' 'SE044' 'SE045' 'SE046'\n",
      " 'SE047' 'SE048' 'SE049' 'SE050' 'SE051' 'SE052' 'SE053' 'SE054' 'SE055'\n",
      " 'SE056' 'SE057' 'SE058' 'SE059' 'SE060' 'SE061' 'SE062' 'SE063' 'SE064'\n",
      " 'SE065' 'SE066' 'SE067' 'SE068' 'SE069' 'SE070' 'SE071' 'SE072' 'SE073'\n",
      " 'SE074' 'SE076' 'SE077' 'SE078' 'SE079' 'SE080' 'SE081' 'SE082' 'SE083'\n",
      " 'SE084' 'SE085' 'SE086' 'SE087' 'SE088' 'SE089' 'SE090' 'SE091' 'SE092'\n",
      " 'SE093' 'SE094' 'SE095' 'SE096' 'SE097' 'SE098' 'SE099' 'SE100' 'SE101'\n",
      " 'SE102' 'SE103' 'SE104' 'SE105' 'SE106' 'SE107' 'SE108' 'SE109' 'SE110'\n",
      " 'SE111' 'SE112' 'SE113' 'SE114' 'SE115' 'SE116' 'SE117' 'SE118' 'SE119'\n",
      " 'SE120' 'SE121' 'SE122' 'SE123' 'SE124' 'SE125' 'SE126' 'SE127' 'SE128'\n",
      " 'SE129' 'SE130' 'SE131' 'SE132' 'SE133' 'SE134' 'SE135' 'SE136' 'SE137'\n",
      " 'SE138' 'SE139' 'SE140' 'SE141' 'SE142' 'SE143' 'SE144' 'SE145' 'SE146'\n",
      " 'SE147' 'SE148' 'SE149' 'SE150' 'SE151' 'SE152' 'SE153' 'SE154' 'SE155'\n",
      " 'SE156' 'SE157' 'SE158' 'SE159' 'SE160' 'SE161' 'SE162' 'SE163' 'SE164'\n",
      " 'SE165']\n",
      "(2448, 275)\n",
      "(613, 275)\n",
      "Tempo de treino: 173.03680939998594\n",
      "14.618380600323071 0.5447192085072781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='backward', estimator=LR, tol=0.01, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b1d1d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T01' 'T02' 'T03' 'T04' 'T05' 'T06' 'T07' 'T08' 'T09' 'T10' 'T11' 'T12'\n",
      " 'T13' 'T14' 'T15' 'T16' 'T17' 'BDGD01' 'BDGD02' 'BDGD03' 'BDGD04'\n",
      " 'BDGD05' 'BDGD06' 'BDGD07' 'BDGD09' 'BDGD10' 'BDGD11' 'BDGD12' 'BDGD13'\n",
      " 'BDGD14' 'BDGD15' 'BDGD16' 'BDGD17' 'BDGD18' 'BDGD19' 'BDGD20' 'BDGD21'\n",
      " 'BDGD22' 'BDGD23' 'BDGD24' 'BDGD25' 'BDGD26' 'BDGD27' 'BDGD28' 'BDGD29'\n",
      " 'BDGD30' 'BDGD31' 'BDGD32' 'BDGD33' 'BDGD34' 'BDGD35' 'BDGD36' 'BDGD37'\n",
      " 'BDGD38' 'BDGD39' 'BDGD40' 'BDGD41' 'BDGD42' 'BDGD43' 'BDGD44' 'BDGD45'\n",
      " 'BDGD46' 'BDGD47' 'BDGD48' 'BDGD49' 'BDGD50' 'BDGD51' 'BDGD52' 'BDGD53'\n",
      " 'BDGD54' 'BDGD55' 'BDGD56' 'BDGD57' 'BDGD58' 'BDGD59' 'BDGD60' 'C01'\n",
      " 'C02' 'C03' 'C04' 'C05' 'C06' 'C07' 'C08' 'C09' 'C10' 'C11' 'C12' 'C13'\n",
      " 'C14' 'C15' 'C16' 'C17' 'C18' 'C19' 'C20' 'C21' 'C22' 'C23' 'C24' 'C25'\n",
      " 'C26' 'C27' 'C28' 'C29' 'C30' 'C31' 'C32' 'C33' 'C35' 'C36' 'SE001'\n",
      " 'SE002' 'SE003' 'SE004' 'SE005' 'SE006' 'SE007' 'SE008' 'SE009' 'SE010'\n",
      " 'SE011' 'SE012' 'SE013' 'SE014' 'SE015' 'SE016' 'SE017' 'SE018' 'SE019'\n",
      " 'SE020' 'SE021' 'SE022' 'SE023' 'SE024' 'SE025' 'SE026' 'SE027' 'SE028'\n",
      " 'SE029' 'SE030' 'SE031' 'SE032' 'SE033' 'SE034' 'SE035' 'SE036' 'SE037'\n",
      " 'SE038' 'SE039' 'SE040' 'SE041' 'SE042' 'SE043' 'SE044' 'SE045' 'SE046'\n",
      " 'SE047' 'SE048' 'SE049' 'SE050' 'SE051' 'SE052' 'SE053' 'SE054' 'SE055'\n",
      " 'SE056' 'SE057' 'SE058' 'SE059' 'SE060' 'SE061' 'SE062' 'SE063' 'SE064'\n",
      " 'SE065' 'SE066' 'SE067' 'SE068' 'SE069' 'SE070' 'SE071' 'SE072' 'SE073'\n",
      " 'SE074' 'SE076' 'SE077' 'SE078' 'SE079' 'SE080' 'SE081' 'SE082' 'SE083'\n",
      " 'SE084' 'SE085' 'SE086' 'SE087' 'SE088' 'SE089' 'SE090' 'SE091' 'SE092'\n",
      " 'SE093' 'SE094' 'SE095' 'SE096' 'SE097' 'SE098' 'SE099' 'SE100' 'SE101'\n",
      " 'SE102' 'SE103' 'SE104' 'SE105' 'SE106' 'SE107' 'SE108' 'SE109' 'SE110'\n",
      " 'SE111' 'SE112' 'SE113' 'SE114' 'SE115' 'SE116' 'SE117' 'SE118' 'SE119'\n",
      " 'SE120' 'SE121' 'SE122' 'SE123' 'SE124' 'SE125' 'SE126' 'SE127' 'SE128'\n",
      " 'SE129' 'SE130' 'SE131' 'SE132' 'SE133' 'SE134' 'SE135' 'SE136' 'SE137'\n",
      " 'SE138' 'SE139' 'SE140' 'SE141' 'SE142' 'SE143' 'SE144' 'SE145' 'SE146'\n",
      " 'SE147' 'SE148' 'SE149' 'SE150' 'SE151' 'SE152' 'SE153' 'SE154' 'SE155'\n",
      " 'SE156' 'SE157' 'SE158' 'SE159' 'SE160' 'SE161' 'SE162' 'SE163' 'SE164'\n",
      " 'SE165']\n",
      "(2448, 275)\n",
      "(613, 275)\n",
      "Tempo de treino: 172.6979207000113\n",
      "14.618380600323071 0.5447192085072781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='backward', estimator=LR, tol=0.001, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db1f0f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características selecionadas: ['T01' 'T02' 'T03' 'T04' 'T05' 'T06' 'T07' 'T08' 'T09' 'T10' 'T11' 'T12'\n",
      " 'T13' 'T14' 'T15' 'T16' 'T17' 'BDGD01' 'BDGD02' 'BDGD03' 'BDGD04'\n",
      " 'BDGD05' 'BDGD06' 'BDGD07' 'BDGD09' 'BDGD10' 'BDGD11' 'BDGD12' 'BDGD13'\n",
      " 'BDGD14' 'BDGD15' 'BDGD16' 'BDGD17' 'BDGD18' 'BDGD19' 'BDGD20' 'BDGD21'\n",
      " 'BDGD22' 'BDGD23' 'BDGD24' 'BDGD25' 'BDGD26' 'BDGD27' 'BDGD28' 'BDGD29'\n",
      " 'BDGD30' 'BDGD31' 'BDGD32' 'BDGD33' 'BDGD34' 'BDGD35' 'BDGD36' 'BDGD37'\n",
      " 'BDGD38' 'BDGD39' 'BDGD40' 'BDGD41' 'BDGD42' 'BDGD43' 'BDGD44' 'BDGD45'\n",
      " 'BDGD46' 'BDGD47' 'BDGD48' 'BDGD49' 'BDGD50' 'BDGD51' 'BDGD52' 'BDGD53'\n",
      " 'BDGD54' 'BDGD55' 'BDGD56' 'BDGD57' 'BDGD58' 'BDGD59' 'BDGD60' 'C01'\n",
      " 'C02' 'C03' 'C04' 'C05' 'C06' 'C07' 'C08' 'C09' 'C10' 'C11' 'C12' 'C13'\n",
      " 'C14' 'C15' 'C16' 'C17' 'C18' 'C19' 'C20' 'C21' 'C22' 'C23' 'C24' 'C25'\n",
      " 'C26' 'C27' 'C28' 'C29' 'C30' 'C31' 'C32' 'C33' 'C35' 'C36' 'SE001'\n",
      " 'SE002' 'SE003' 'SE004' 'SE005' 'SE006' 'SE007' 'SE008' 'SE009' 'SE010'\n",
      " 'SE011' 'SE012' 'SE013' 'SE014' 'SE015' 'SE016' 'SE017' 'SE018' 'SE019'\n",
      " 'SE020' 'SE021' 'SE022' 'SE023' 'SE024' 'SE025' 'SE026' 'SE027' 'SE028'\n",
      " 'SE029' 'SE030' 'SE031' 'SE032' 'SE033' 'SE034' 'SE035' 'SE036' 'SE037'\n",
      " 'SE038' 'SE039' 'SE040' 'SE041' 'SE042' 'SE043' 'SE044' 'SE045' 'SE046'\n",
      " 'SE047' 'SE048' 'SE049' 'SE050' 'SE051' 'SE052' 'SE053' 'SE054' 'SE055'\n",
      " 'SE056' 'SE057' 'SE058' 'SE059' 'SE060' 'SE061' 'SE062' 'SE063' 'SE064'\n",
      " 'SE065' 'SE066' 'SE067' 'SE068' 'SE069' 'SE070' 'SE071' 'SE072' 'SE073'\n",
      " 'SE074' 'SE076' 'SE077' 'SE078' 'SE079' 'SE080' 'SE081' 'SE082' 'SE083'\n",
      " 'SE084' 'SE085' 'SE086' 'SE087' 'SE088' 'SE089' 'SE090' 'SE091' 'SE092'\n",
      " 'SE093' 'SE094' 'SE095' 'SE096' 'SE097' 'SE098' 'SE099' 'SE100' 'SE101'\n",
      " 'SE102' 'SE103' 'SE104' 'SE105' 'SE106' 'SE107' 'SE108' 'SE109' 'SE110'\n",
      " 'SE111' 'SE112' 'SE113' 'SE114' 'SE115' 'SE116' 'SE117' 'SE118' 'SE119'\n",
      " 'SE120' 'SE121' 'SE122' 'SE123' 'SE124' 'SE125' 'SE126' 'SE127' 'SE128'\n",
      " 'SE129' 'SE130' 'SE131' 'SE132' 'SE133' 'SE134' 'SE135' 'SE136' 'SE137'\n",
      " 'SE138' 'SE139' 'SE140' 'SE141' 'SE142' 'SE143' 'SE144' 'SE145' 'SE146'\n",
      " 'SE147' 'SE148' 'SE149' 'SE150' 'SE151' 'SE152' 'SE153' 'SE154' 'SE155'\n",
      " 'SE156' 'SE157' 'SE158' 'SE159' 'SE160' 'SE161' 'SE162' 'SE163' 'SE164'\n",
      " 'SE165']\n",
      "(2448, 275)\n",
      "(613, 275)\n",
      "Tempo de treino: 172.95679910000763\n",
      "14.618380600323071 0.5447192085072781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "SFS = SequentialFeatureSelector(direction='backward', estimator=LR, tol=0.0001, scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "SFS.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo a máscara de características selecionadas\n",
    "selected_features_mask = SFS.get_support()\n",
    "\n",
    "# Usando a máscara para obter os nomes das características selecionadas\n",
    "selected_features = np.array(feature_names)[selected_features_mask]\n",
    "\n",
    "# Imprimindo os nomes das características selecionadas\n",
    "print(\"Características selecionadas:\", selected_features)\n",
    "\n",
    "X_train_selected = SFS.transform(X_train)\n",
    "X_test_selected = SFS.transform(X_test)\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "print(X_test_selected.shape)\n",
    "\n",
    "#Agora está sendo treinada uma regressão linear utilizando as características selecionadas pela SequencialFeatureSelector\n",
    "LR.fit(X_train_selected, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test, LR.predict(X_test_selected))\n",
    "Rsquared = metrics.r2_score(y_test, LR.predict(X_test_selected))\n",
    "\n",
    "print(\"Tempo de treino:\", end_time - start_time)\n",
    "print(MSE, Rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6e213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
